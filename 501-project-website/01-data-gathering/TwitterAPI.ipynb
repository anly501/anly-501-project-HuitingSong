{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter API \n",
    "## In Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used twitter API to scratch mutiple keywords:**\"energy\" \"energy economy\" \"consumption\" \"data\" \"USA\"** to gather comments from twiter about their opinion about the energy consumption and energy economy. I use these data to analyze the positive and negative opinion. I can detect the internet users' attitudes to energy influence on economy. I can also use this datasets to define the relationship between economy and data. The keywords may not clear enough for me to analysis but I will adjust it later for future research. I used for loop to search over 600 tweets in order to make comprehensive datasets. I will collect more in the future to scratch over 2000 tweets in order to make sure my results are accurate. I plan to detect the frequency of words to gain a plot. More than this, I plan to use Naive Bytes to give each tweet a positive or negative attitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "# READ FILE\n",
    "f = open(\"api-keys.json\")\n",
    "input=json.load(f); #print(input)\n",
    "\n",
    "# LOAD KEYS INTO API\n",
    "consumer_key=input[\"consumer_key\"]    \n",
    "consumer_secret=input[\"consumer_secret\"]    \n",
    "access_token=input[\"access_token\"]    \n",
    "access_token_secret=input[\"access_token_secret\"]    \n",
    "bearer_token=input[\"bearer_token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import requests\n",
    "# Set up Connection\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the search_twitter function here.\n",
    "def search_twitter(query, max_results,tweet_fields, bearer_token = bearer_token):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    url = \"https://api.twitter.com/2/tweets/search/recent?query={}&max_results={}&{}\".format(query, max_results,tweet_fields)\n",
    "    print(\"--------------\",url,\"--------------\")\n",
    "    response = requests.request(\"GET\", url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_fields = \"tweet.fields=text,author_id,created_at,lang\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- https://api.twitter.com/2/tweets/search/recent?query=energy&max_results=100&tweet.fields=text,author_id,created_at,lang --------------\n",
      "-------------- https://api.twitter.com/2/tweets/search/recent?query=energy&max_results=100&tweet.fields=text,author_id,created_at,lang --------------\n",
      "-------------- https://api.twitter.com/2/tweets/search/recent?query=energy&max_results=100&tweet.fields=text,author_id,created_at,lang --------------\n",
      "-------------- https://api.twitter.com/2/tweets/search/recent?query=energy&max_results=100&tweet.fields=text,author_id,created_at,lang --------------\n",
      "-------------- https://api.twitter.com/2/tweets/search/recent?query=energy&max_results=100&tweet.fields=text,author_id,created_at,lang --------------\n",
      "-------------- https://api.twitter.com/2/tweets/search/recent?query=energy&max_results=100&tweet.fields=text,author_id,created_at,lang --------------\n",
      "-------------- https://api.twitter.com/2/tweets/search/recent?query=energy economy&max_results=100&tweet.fields=text,author_id,created_at,lang --------------\n",
      "-------------- https://api.twitter.com/2/tweets/search/recent?query=energy economy&max_results=100&tweet.fields=text,author_id,created_at,lang --------------\n",
      "-------------- https://api.twitter.com/2/tweets/search/recent?query=energy economy&max_results=100&tweet.fields=text,author_id,created_at,lang --------------\n",
      "-------------- https://api.twitter.com/2/tweets/search/recent?query=energy economy&max_results=100&tweet.fields=text,author_id,created_at,lang --------------\n",
      "-------------- https://api.twitter.com/2/tweets/search/recent?query=energy economy&max_results=100&tweet.fields=text,author_id,created_at,lang --------------\n",
      "-------------- https://api.twitter.com/2/tweets/search/recent?query=energy economy&max_results=100&tweet.fields=text,author_id,created_at,lang --------------\n",
      "-------------- https://api.twitter.com/2/tweets/search/recent?query=consumption&max_results=100&tweet.fields=text,author_id,created_at,lang --------------\n",
      "-------------- https://api.twitter.com/2/tweets/search/recent?query=consumption&max_results=100&tweet.fields=text,author_id,created_at,lang --------------\n",
      "-------------- https://api.twitter.com/2/tweets/search/recent?query=consumption&max_results=100&tweet.fields=text,author_id,created_at,lang --------------\n",
      "-------------- https://api.twitter.com/2/tweets/search/recent?query=consumption&max_results=100&tweet.fields=text,author_id,created_at,lang --------------\n",
      "-------------- https://api.twitter.com/2/tweets/search/recent?query=consumption&max_results=100&tweet.fields=text,author_id,created_at,lang --------------\n",
      "-------------- https://api.twitter.com/2/tweets/search/recent?query=consumption&max_results=100&tweet.fields=text,author_id,created_at,lang --------------\n",
      "-------------- https://api.twitter.com/2/tweets/search/recent?query=data&max_results=100&tweet.fields=text,author_id,created_at,lang --------------\n",
      "-------------- https://api.twitter.com/2/tweets/search/recent?query=data&max_results=100&tweet.fields=text,author_id,created_at,lang --------------\n",
      "-------------- https://api.twitter.com/2/tweets/search/recent?query=data&max_results=100&tweet.fields=text,author_id,created_at,lang --------------\n",
      "-------------- https://api.twitter.com/2/tweets/search/recent?query=data&max_results=100&tweet.fields=text,author_id,created_at,lang --------------\n",
      "-------------- https://api.twitter.com/2/tweets/search/recent?query=data&max_results=100&tweet.fields=text,author_id,created_at,lang --------------\n",
      "-------------- https://api.twitter.com/2/tweets/search/recent?query=data&max_results=100&tweet.fields=text,author_id,created_at,lang --------------\n",
      "-------------- https://api.twitter.com/2/tweets/search/recent?query=USA&max_results=100&tweet.fields=text,author_id,created_at,lang --------------\n",
      "-------------- https://api.twitter.com/2/tweets/search/recent?query=USA&max_results=100&tweet.fields=text,author_id,created_at,lang --------------\n",
      "-------------- https://api.twitter.com/2/tweets/search/recent?query=USA&max_results=100&tweet.fields=text,author_id,created_at,lang --------------\n",
      "-------------- https://api.twitter.com/2/tweets/search/recent?query=USA&max_results=100&tweet.fields=text,author_id,created_at,lang --------------\n",
      "-------------- https://api.twitter.com/2/tweets/search/recent?query=USA&max_results=100&tweet.fields=text,author_id,created_at,lang --------------\n",
      "-------------- https://api.twitter.com/2/tweets/search/recent?query=USA&max_results=100&tweet.fields=text,author_id,created_at,lang --------------\n"
     ]
    }
   ],
   "source": [
    "data = \"/Users/apple/Desktop/anly-501-project-HuitingSong/codes/01-data-gathering\"\n",
    "search_tweets = [\"energy\",\"energy economy\",\"consumption\",\"data\",\"USA\"]\n",
    "for idx,val in enumerate(search_tweets):\n",
    "    tweets_jsondump = []\n",
    "    json_response1 = search_twitter(query = str(val), max_results = 100, tweet_fields = tweet_fields, bearer_token=bearer_token)\n",
    "    json_response2 = search_twitter(query = str(val), max_results = 100, tweet_fields = tweet_fields, bearer_token=bearer_token)\n",
    "    json_response3 = search_twitter(query = str(val), max_results = 100, tweet_fields = tweet_fields, bearer_token=bearer_token)\n",
    "    json_response4 = search_twitter(query = str(val), max_results = 100, tweet_fields = tweet_fields, bearer_token=bearer_token)\n",
    "    json_response5 = search_twitter(query = str(val), max_results = 100, tweet_fields = tweet_fields, bearer_token=bearer_token)\n",
    "    json_response6 = search_twitter(query = str(val), max_results = 100, tweet_fields = tweet_fields, bearer_token=bearer_token)\n",
    "    for i in json_response1['data']:\n",
    "        tweets_jsondump.append(i)\n",
    "    for i in json_response2['data']:\n",
    "        tweets_jsondump.append(i)\n",
    "    for i in json_response3['data']:\n",
    "        tweets_jsondump.append(i)\n",
    "    for i in json_response4['data']:\n",
    "        tweets_jsondump.append(i)\n",
    "    for i in json_response5['data']:\n",
    "        tweets_jsondump.append(i)\n",
    "    for i in json_response6['data']:\n",
    "        tweets_jsondump.append(i)\n",
    "    with open(data+str(val)+'.json','w') as json_file:\n",
    "        json.dump(tweets_jsondump,json_file)\n",
    "        json_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>edit_history_tweet_ids</th>\n",
       "      <th>lang</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1051520409533931521</td>\n",
       "      <td>2022-11-23T00:29:26.000Z</td>\n",
       "      <td>@dadguykek @Darkeusito @hikarushom FOOTBALL IS...</td>\n",
       "      <td>[1595212895549366272]</td>\n",
       "      <td>en</td>\n",
       "      <td>1595212895549366272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>185695656</td>\n",
       "      <td>2022-11-23T00:29:26.000Z</td>\n",
       "      <td>RT @claudineteressa: Mountain VayCay NY , USA…...</td>\n",
       "      <td>[1595212894706311169]</td>\n",
       "      <td>fi</td>\n",
       "      <td>1595212894706311169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1467481155096227842</td>\n",
       "      <td>2022-11-23T00:29:26.000Z</td>\n",
       "      <td>@WSMITHROOM101 @0ccultbot Not only USA my friend.</td>\n",
       "      <td>[1595212894068789249]</td>\n",
       "      <td>en</td>\n",
       "      <td>1595212894068789249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1116893977012314114</td>\n",
       "      <td>2022-11-23T00:29:26.000Z</td>\n",
       "      <td>@josefheynckes Es ist ja nicht so, dass man si...</td>\n",
       "      <td>[1595212893405986817]</td>\n",
       "      <td>de</td>\n",
       "      <td>1595212893405986817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2360231094</td>\n",
       "      <td>2022-11-23T00:29:25.000Z</td>\n",
       "      <td>RT @Daily_JK97: [MEDIA] “Dreamers” by Jungkook...</td>\n",
       "      <td>[1595212892378320896]</td>\n",
       "      <td>en</td>\n",
       "      <td>1595212892378320896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1425641676295471105</td>\n",
       "      <td>2022-11-23T00:29:00.000Z</td>\n",
       "      <td>@harley72268373 @larry_vu11 @globaltimesnews S...</td>\n",
       "      <td>[1595212786619252736]</td>\n",
       "      <td>en</td>\n",
       "      <td>1595212786619252736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1566112031249408001</td>\n",
       "      <td>2022-11-23T00:29:00.000Z</td>\n",
       "      <td>RT @iabfirenze: @iabfirenze | PHOTOSHOOTING \\n...</td>\n",
       "      <td>[1595212785935421440]</td>\n",
       "      <td>en</td>\n",
       "      <td>1595212785935421440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>968907124423131137</td>\n",
       "      <td>2022-11-23T00:29:00.000Z</td>\n",
       "      <td>carlyjae During the obama/biden reign, I poste...</td>\n",
       "      <td>[1595212785633628160]</td>\n",
       "      <td>en</td>\n",
       "      <td>1595212785633628160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>935412302299332608</td>\n",
       "      <td>2022-11-23T00:29:00.000Z</td>\n",
       "      <td>RT @PrettyChay7: Bellaa Wind Chimes American F...</td>\n",
       "      <td>[1595212785608056833]</td>\n",
       "      <td>en</td>\n",
       "      <td>1595212785608056833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>117613017</td>\n",
       "      <td>2022-11-23T00:29:00.000Z</td>\n",
       "      <td>RT @Saturday_am: Who's watching the #WorldCup2...</td>\n",
       "      <td>[1595212785604083714]</td>\n",
       "      <td>en</td>\n",
       "      <td>1595212785604083714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              author_id                created_at  \\\n",
       "0   1051520409533931521  2022-11-23T00:29:26.000Z   \n",
       "1             185695656  2022-11-23T00:29:26.000Z   \n",
       "2   1467481155096227842  2022-11-23T00:29:26.000Z   \n",
       "3   1116893977012314114  2022-11-23T00:29:26.000Z   \n",
       "4            2360231094  2022-11-23T00:29:25.000Z   \n",
       "..                  ...                       ...   \n",
       "95  1425641676295471105  2022-11-23T00:29:00.000Z   \n",
       "96  1566112031249408001  2022-11-23T00:29:00.000Z   \n",
       "97   968907124423131137  2022-11-23T00:29:00.000Z   \n",
       "98   935412302299332608  2022-11-23T00:29:00.000Z   \n",
       "99            117613017  2022-11-23T00:29:00.000Z   \n",
       "\n",
       "                                                 text edit_history_tweet_ids  \\\n",
       "0   @dadguykek @Darkeusito @hikarushom FOOTBALL IS...  [1595212895549366272]   \n",
       "1   RT @claudineteressa: Mountain VayCay NY , USA…...  [1595212894706311169]   \n",
       "2   @WSMITHROOM101 @0ccultbot Not only USA my friend.  [1595212894068789249]   \n",
       "3   @josefheynckes Es ist ja nicht so, dass man si...  [1595212893405986817]   \n",
       "4   RT @Daily_JK97: [MEDIA] “Dreamers” by Jungkook...  [1595212892378320896]   \n",
       "..                                                ...                    ...   \n",
       "95  @harley72268373 @larry_vu11 @globaltimesnews S...  [1595212786619252736]   \n",
       "96  RT @iabfirenze: @iabfirenze | PHOTOSHOOTING \\n...  [1595212785935421440]   \n",
       "97  carlyjae During the obama/biden reign, I poste...  [1595212785633628160]   \n",
       "98  RT @PrettyChay7: Bellaa Wind Chimes American F...  [1595212785608056833]   \n",
       "99  RT @Saturday_am: Who's watching the #WorldCup2...  [1595212785604083714]   \n",
       "\n",
       "   lang                   id  \n",
       "0    en  1595212895549366272  \n",
       "1    fi  1595212894706311169  \n",
       "2    en  1595212894068789249  \n",
       "3    de  1595212893405986817  \n",
       "4    en  1595212892378320896  \n",
       "..  ...                  ...  \n",
       "95   en  1595212786619252736  \n",
       "96   en  1595212785935421440  \n",
       "97   en  1595212785633628160  \n",
       "98   en  1595212785608056833  \n",
       "99   en  1595212785604083714  \n",
       "\n",
       "[600 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import json_normalize \n",
    "import pandas as pd\n",
    "twitterdf1 = json_normalize(json_response1,\"data\")\n",
    "twitterdf2 = json_normalize(json_response2,\"data\")\n",
    "twitterdf3 = json_normalize(json_response3,\"data\")\n",
    "twitterdf4 = json_normalize(json_response4,\"data\")\n",
    "twitterdf5 = json_normalize(json_response5,\"data\")\n",
    "twitterdf6 = json_normalize(json_response6,\"data\")\n",
    "twitterdf = [twitterdf1,twitterdf2,twitterdf3,twitterdf4,twitterdf5,twitterdf6]\n",
    "twitterdf = pd.concat(twitterdf)\n",
    "twitterdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitterdf.to_csv(\"/Users/apple/Desktop/anly-501-project-HuitingSong/codes/01-data-gathering/twitterpython.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ANLY501')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9261db5222c8f87fd113a6daf33df2e6d85918ea826f24e750f4a5888fb1c92c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
