---
title: "SVM for text data"
pdf-engine: lualatex
format:
  html:
        code-fold: true
        self-contained: true
execute:
    warning: false
---

## Introducation to SVM

Support vector machines (SVMs) are a set of supervised learning methods used for classification, regression and outliers detection. 

The advantages of support vector machines are:
    - Effective in high dimensional spaces. 
    - Still effective in cases where number of dimensions is greater than the number of samples.
    - Uses a subset of training points in the decision function (called support vectors), so it is also memory efficient
    - Versatile: different Kernel functions can be specified for the decision function. Common kernels are provided, but it is also possible to specify custom kernels.

The disadvantages of support vector machines include:
    - If the number of features is much greater than the number of samples, avoid over-fitting in choosing Kernel functions and regularization term is crucial.
    - SVMs do not directly provide probability estimates, these are calculated using an expensive five-fold cross-validation.

Reference: https://scikit-learn.org/stable/modules/svm.html 

## Dataset Introduction

## dataset of text data collected in python

People's perception of energy consumption is very important. It not only reflects the public's perception, but also indirectly reflects people's concern for environmental issues and their willingness to change the status quo. In this section, I will the dataset that cleaned before with content about twitter user's sentiment about energy and enviornment to do the SVM. The purpose of this section for me is to see how the sentiment analysis goes and can i really get the sentiment about the dataset. and then, this influence my study of knowing how people think about energy and envirnment.

The dataset contains the information:
        - Unnamed: 0 : The repeated number id of each content which will be cleaned while importing the dataset
        - text: Each text review from twitter users
        - clean_text: The text which has been cleaned
        - result: Sentiment classification of each text (Positive, Neutral, Negative)
        - neg,neu,pos: the score generated by sentiment analysis model 
        - compound: the sentiment score we utilize to do caegorize for positive, neutral, negative.

             (The compound score is the sum of positive, negative & neutral scores which is then normalized between -1(most extreme negative) and +1 (most extreme positive). The more Compound score closer to +1, the higher the positivity of the text.)
 

## Step of SVM

**load packages and dataset**
```{python}
import pandas as pd
import numpy as np
from nltk.tokenize import word_tokenize
from nltk import pos_tag
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from sklearn.preprocessing import LabelEncoder
from collections import defaultdict
from nltk.corpus import wordnet as wn
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn import model_selection, naive_bayes, svm
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns
from bs4 import BeautifulSoup
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.metrics import classification_report, pair_confusion_matrix

stm = pd.read_csv("/Users/crystal/Desktop/anly-501-project-HuitingSong/501-project-website/data/cleaned data/stm_r_label.csv",index_col=[0])
stm.head()
```

**Basic EDA**
```{python}
stm['sentiment'].value_counts().plot(kind="bar")
plt.title("The counts for each sentiment labels")
```

As the graph shown, twitter users' with negative sentiment are the most, and people with neutral sentiment are the least. This indicates that most of twitter users in my dataset hold negative views toward the different type of energy and enviornment concern.

**Data processing** 

- to remove the irrelevent items in text and get dummies
```{python}
import re

REPLACE_BY_SPACE_RE = re.compile('[/(){}\[\]\|@,;]')
BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')
STOPWORDS = set(stopwords.words('english'))

def cleanText(text):
    text = BeautifulSoup(text, "lxml").text
    text = text.lower()
    text = text.replace("rt","") # remove the word `rt` which is shown in the begining of every sentence
    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text
    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text
    text = ' '.join(word for word in text.split() if word not in STOPWORDS) 
    return text

stm['clean_text'] = stm['clean_text'].apply(cleanText)
stm.head()
```

- Dummy the column `sentiment` with value between 0 and 1 and 2. 0 represents Negative, 1 represents Neutral, 2 represnets Positive
```{python}
stm["sentiment"] = stm["sentiment"].replace("negative",'0')
stm["sentiment"] = stm["sentiment"].replace("neutral",'1')
stm["sentiment"] = stm["sentiment"].replace("positive",'2')
stm["sentiment"] = stm["sentiment"].astype("category")
stm.head()
```

**split the dataset into traning set (80%) and test set (20%)** 
```{python}
from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test=train_test_split(stm['clean_text'],stm['sentiment'],test_size=0.2)
```

**Performs the TF-IDF transformation**

In the data cleaning section, I use bag of word method to model converts text into fixed-length vectors by counting how many times each word appears. Here, i will use TF-IDF which is Term Frequency Inverse Document Frequency. TFIDF works by proportionally increasing the number of times a word appears in the document but is counterbalanced by the number of documents in which it is present. Hence, words like ‘this’, ’are’ etc., that are commonly present in all the documents are not given a very high rank. 

First, the "TfidfVectorizer" function converts a collection of raw documents into a matrix of TF-IDF features. The stop_words_ attribute can get large and increase the model size when pickling.
```{python}
tfidf = TfidfVectorizer(stop_words= 'english', sublinear_tf= True)
tfidf
```

Second, I fit the x_train data into the TF-IDF and transform them to get the tf-idf scores of a set of sentences. 

I print the result of TF-IDF score matching with tokens, so you can what exactly TF-IDF do here and what it does.

```{python}
tfidf_fitted = tfidf.fit(x_train)
tfidf_scores_train = tfidf_fitted.transform(x_train)

# to see how the tfidf score the tokens
# get the first vector out for x_train
first_vec=tfidf_scores_train[0] 
# place tf-idf values in a pandas data frame 
df = pd.DataFrame(first_vec.T.todense(), index=tfidf.get_feature_names(), columns=["tfidf"]) 
df.head
```

**Train the SVM model**
```{python}
# train set
SVC = svm.SVC()
model = SVC.fit(tfidf_scores_train,y_train)
yp_train = model.predict(tfidf_scores_train)

# train model on test set
tfidf_scores_test = tfidf_fitted.transform(x_test)
yp_test = model.predict(tfidf_scores_test)
```


**Display the training result of classification report**
```{python}
# Save the results in a data frame. 
dic_train = classification_report(y_train,yp_train,output_dict=True)
dic_test = classification_report(y_test,yp_test,output_dict=True)
result_train = pd.DataFrame.from_dict(dic_train)
result_train = result_train.transpose()
result_test = pd.DataFrame.from_dict(dic_test)
result_test = result_test.transpose()
```
```{python}
print("result dataframe of train dataset:")
print(result_train)
print("result dataframe of test dataset:")
print(result_test)
```

From the classification report, we can see that the accuracy on train set is 75% and after training on the test dataset, we get 63% accuracy. Then, this indicate that SVM model has 63% possibility of accuratly predict the sentiment labels of dataset.

**get the confusion matrix**
```{python}
print("classification report of test data:")
print(ConfusionMatrixDisplay.from_predictions(y_train,yp_train))
```
```{python}
print("classification report of test data:")
print(ConfusionMatrixDisplay.from_predictions(y_test,yp_test))
```

From the confusion matrix, we can clearly notice that the SVM model does not correctly predict the label of 'Neutral' at all. Since in the beginning of this section, we get info from EDA that most of sentiments is negative. So, take a look at the negative sentiment prediction after training the model on test set, we get 93 labels correctly in negative and 11 incorrectly. 

As we can see, the classification report and the confusion matrix shows that the acucracy of model is 63%, which we can conclude SVM is a fairly good model to predict the sentiment analysis of this text dataset. However, in the last Naive Bayes classifier, we get 65% accuracy in Multinomial NB classifier. Since the accuracy is higher than the SVM model provided, right now we still consider Naive Bayes as our sentiment label prediction model.